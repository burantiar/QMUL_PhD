{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81bef5aa",
   "metadata": {},
   "source": [
    "If you are working on Google Colab, do the following after you copy the files in the designated folder on your Google Drive:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db6896d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "import os\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "os.chdir(os.path.join(os.getcwd(), 'drive', 'My Drive', 'Colab Notebooks'))\n",
    "os.listdir()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b20db63b",
   "metadata": {},
   "source": [
    "# Strings, regular expressions and working with text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a87a833",
   "metadata": {},
   "source": [
    "## Recap: string data type"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63272806",
   "metadata": {},
   "source": [
    "- a srting is a sequence of characters\n",
    "- a string literal uses quotes: \"Hello!\" or 'Hello': does not matter which one you use, just make sure to use the same one in the beginning and the end. These variability is done on purpose: we'll come back to these later...\n",
    "- for strings, + means concatenate\n",
    "- we can use different buil-it functions to work with strings\n",
    "- when a sring contains numbers, it is still a string\n",
    "- we can convert numbers in a string into a number using int()\n",
    "- we can convert numbers to strings using str()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7ba497f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#'len' function shows the length of a string\n",
    "# remember: a function is a stored code that we stroe somewhere and call when we need it \n",
    "fruit = 'banana'\n",
    "len(fruit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "24492e35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 b\n",
      "1 a\n",
      "2 n\n",
      "3 a\n",
      "4 n\n",
      "5 a\n"
     ]
    }
   ],
   "source": [
    "# looping through strings\n",
    "\n",
    "fruit = 'banana'\n",
    "index  = 0\n",
    "while index < len(fruit):\n",
    "    letter = fruit[index]\n",
    "    print(index,letter)\n",
    "    index = index +1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3d0bf4d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b\n",
      "a\n",
      "n\n",
      "a\n",
      "n\n",
      "a\n"
     ]
    }
   ],
   "source": [
    "# a simpler way to do the same thing is using a for statement\n",
    "fruit = 'banana'\n",
    "for letter in fruit:\n",
    "    print(letter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "15377fc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "word = 'banana'\n",
    "count = 0\n",
    "for letter in word:\n",
    "    if letter =='a':\n",
    "        count = count +1\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5c86c63c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this class is super!\n"
     ]
    }
   ],
   "source": [
    "# slicing strings\n",
    "\n",
    "my_string = \"this class is super super boring and I want to sleep\"\n",
    "\n",
    "print(my_string[0:19] + \"!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "310e147b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this class is super\n",
      " super boring and I want to sleep\n"
     ]
    }
   ],
   "source": [
    "# it's common to either eliminate the first or the second part of the range, \n",
    "# which means \"count from the start up to X\"\n",
    "\n",
    "print(my_string[:19])\n",
    "\n",
    "# or the second part of the string\n",
    "\n",
    "print(my_string[19:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c9bab880",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this class is super super boring and I want to sleep\n"
     ]
    }
   ],
   "source": [
    "# or eliminate them both if you really want to\n",
    "print(my_string[:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "96f00bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise: count all 's' in my_string\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "856c1d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "str1 = \"Hello\"\n",
    "str2 = 'there'\n",
    "output = str1 + str2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ca7a44c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hellothere\n"
     ]
    }
   ],
   "source": [
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b47f69a",
   "metadata": {},
   "source": [
    "Question: how do I insert a space?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7657bf57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# enter your answer here\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4f060840",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can only concatenate str (not \"int\") to str",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/y3/6n_z927d0hscr4lz6c4gvsjc0000gn/T/ipykernel_25045/1370979626.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mstr3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'123'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr3\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: can only concatenate str (not \"int\") to str"
     ]
    }
   ],
   "source": [
    "#working with numbers in the string:\n",
    "\n",
    "str3 = '123'\n",
    "x = str3+ 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf91152f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# how to correct it?\n",
    "\n",
    "__________\n",
    "\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3c0e1c73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#using \"in\" as a logical operator\n",
    "\n",
    "'nan' in fruit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6ea369bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'BANANA'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# other string functions\n",
    "fruit.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e83480e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "word = \"MAMA\"\n",
    "word._____()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d2c3efd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c58fb263",
   "metadata": {},
   "outputs": [],
   "source": [
    "word. [TAB] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8460806e",
   "metadata": {},
   "source": [
    "# Regular expressions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cea8b1f",
   "metadata": {},
   "source": [
    "Regular expressions (called REs, or regexes, or regex patterns) are essentially a tiny, highly specialized programming language embedded inside Python and made available through the *re* module. Using this little language, you specify the rules for the set of possible strings that you want to match; this set might contain English sentences, or e-mail addresses, or TeX commands, or anything you like. You can then ask questions such as “Does this string match the pattern?”, or “Is there a match for the pattern anywhere in this string?”. You can also use REs to modify a string or to split it apart in various ways.\n",
    "\n",
    "Read more here: https://docs.python.org/3/howto/regex.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d448b360",
   "metadata": {},
   "source": [
    "## Regular expressions cheat sheet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c6a0d32",
   "metadata": {},
   "source": [
    "**Python Regular Expression Quick Guide**\n",
    "\n",
    "**^**        - Matches the beginning of a line\n",
    "\n",
    "$        - Matches the end of the line\n",
    "\n",
    ".        - Matches any character\n",
    "\n",
    "\\s       - Matches whitespace\n",
    "\n",
    "\\S       - Matches any non-whitespace character\n",
    "\n",
    "'*'       - Repeats a character zero or more times\n",
    "\n",
    "*?       - Repeats a character zero or more times \n",
    "         (non-greedy)\n",
    "'+'        - Repeats a character one or more times\n",
    "\n",
    "'+?'       - Repeats a character one or more times \n",
    "         (non-greedy)\n",
    "         \n",
    "[aeiou]  - Matches a single character in the listed set\n",
    "\n",
    "[^XYZ]   - Matches a single character not in the listed set\n",
    "\n",
    "[a-z0-9] - The set of characters can include a range\n",
    "\n",
    "(        - Indicates where string extraction is to start\n",
    "\n",
    ")        - Indicates where string extraction is to end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "225b8afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04faa21d",
   "metadata": {},
   "source": [
    "- you can use **re.search()** to see if a string matches a regular expression\n",
    "- you can ues **re.findall()** to extract portions of a string that match your regular expression, similar to combinations of find() and slicing fruit[0:4] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d96895bd",
   "metadata": {},
   "source": [
    "Now we will work woth a short text file, which contains recent extracts from out emails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3e1323c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From: [Shared] SBM PhD support <sbmphd-support@qmul.ac.uk>\n",
      "From: \"[Shared] SBM PhD support\" <sbmphd-support@qmul.ac.uk>\n",
      "From: \"[Shared] SBM PhD support\" <sbmphd-support@qmul.ac.uk>\n"
     ]
    }
   ],
   "source": [
    "file = open('mailbox.txt')\n",
    "for line in file:\n",
    "    line = line.rstrip() #Remove any white spaces at the end of the string:\n",
    "    if re.search(\"From:\", line):\n",
    "        print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0ef1f0f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To: Kairan Chen <kairan.chen@qmul.ac.uk>; Shang Chen <shang.chen@qmul.ac.uk>; Saeide Jamshidpour Poshtahani <s.jamshidpourposhtahani@qmul.ac.uk>; Zehua Jiang <zehua.jiang@qmul.ac.uk>; Muhammad Taif Khan <taif.khan@qmul.ac.uk>; Shijun Mu <s.mu@qmul.ac.uk>; Ines Saddi Ep Oueslati <i.saddiepoueslati@qmul.ac.uk>; Yuliya Vanzhulova Tavares <y.vanzhulovatavares@qmul.ac.uk>; Guven Demirel <g.demirel@qmul.ac.uk>; Natalia Efremova <n.efremova@qmul.ac.uk>\n",
      "To: Kairan Chen <kairan.chen@qmul.ac.uk>, Shang Chen <shang.chen@qmul.ac.uk>, Saeide Jamshidpour Poshtahani <s.jamshidpourposhtahani@qmul.ac.uk>, Zehua Jiang <zehua.jiang@qmul.ac.uk>, Muhammad Taif Khan <taif.khan@qmul.ac.uk>, Shijun Mu <s.mu@qmul.ac.uk>, Ines Saddi Ep Oueslati <i.saddiepoueslati@qmul.ac.uk>, Yuliya Vanzhulova Tavares <y.vanzhulovatavares@qmul.ac.uk>, Guven Demirel <g.demirel@qmul.ac.uk>, Natalia Efremova <n.efremova@qmul.ac.uk>, Loan Quynh Thi Nguyen <loan.nguyen@qmul.ac.uk>, Minqi Feng <minqi.feng@qmul.ac.uk>\n",
      "To: Kairan Chen <kairan.chen@qmul.ac.uk>, Shang Chen <shang.chen@qmul.ac.uk>, Saeide Jamshidpour Poshtahani <s.jamshidpourposhtahani@qmul.ac.uk>, Zehua Jiang <zehua.jiang@qmul.ac.uk>, Muhammad Taif Khan <taif.khan@qmul.ac.uk>, Shijun Mu <s.mu@qmul.ac.uk>, Ines Saddi Ep Oueslati <i.saddiepoueslati@qmul.ac.uk>, Yuliya Vanzhulova Tavares <y.vanzhulovatavares@qmul.ac.uk>, Guven Demirel <g.demirel@qmul.ac.uk>, Natalia Efremova <n.efremova@qmul.ac.uk>, Loan Quynh Thi Nguyen <loan.nguyen@qmul.ac.uk>, Minqi Feng <minqi.feng@qmul.ac.uk>\n"
     ]
    }
   ],
   "source": [
    "# now we are going to use the \"starts with\" function ^\n",
    "\n",
    "file = open('mailbox.txt')\n",
    "for line in file:\n",
    "    line = line.rstrip()\n",
    "    if re.search(\"^To:\", line):\n",
    "        print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2ae960ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if we want to find a line starting with a word or a character, we can use:\n",
    "# ^D.*\n",
    "# where D is the character at the beginning of the line\n",
    "# . is \"any character\"\n",
    "# and * is \"zero or more times\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5336366d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's look at out file first\n",
    "with open('mailbox.txt') as f:\n",
    "    lines = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8a1f82d2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Dear Isabella,\\n',\n",
       " \"Do we have today's link for the session that will take place at 10. Or we use the same link?\\n\",\n",
       " 'kind regards,\\n',\n",
       " 'Ines\\n',\n",
       " '\\n',\n",
       " 'From: [Shared] SBM PhD support <sbmphd-support@qmul.ac.uk>\\n',\n",
       " 'Sent: 11 May 2022 15:27\\n',\n",
       " 'To: Kairan Chen <kairan.chen@qmul.ac.uk>; Shang Chen <shang.chen@qmul.ac.uk>; Saeide Jamshidpour Poshtahani <s.jamshidpourposhtahani@qmul.ac.uk>; Zehua Jiang <zehua.jiang@qmul.ac.uk>; Muhammad Taif Khan <taif.khan@qmul.ac.uk>; Shijun Mu <s.mu@qmul.ac.uk>; Ines Saddi Ep Oueslati <i.saddiepoueslati@qmul.ac.uk>; Yuliya Vanzhulova Tavares <y.vanzhulovatavares@qmul.ac.uk>; Guven Demirel <g.demirel@qmul.ac.uk>; Natalia Efremova <n.efremova@qmul.ac.uk>\\n',\n",
       " 'Cc: Ashraf D M Abumousa <a.d.abumousa@qmul.ac.uk>; Fatima Ali <fatima.ali@qmul.ac.uk>; Jeffery Essuantsi Bondzie <j.e.bondzie@qmul.ac.uk>; Siddharth Chakravarty <s.chakravarty@qmul.ac.uk>; Shabee Ul Haq <shabee.haq@qmul.ac.uk>; Jiawei Huang <jiawei.huang@qmul.ac.uk>; Nabiyla Risfa Izzati <n.izzati@qmul.ac.uk>; Lan Lu <l.lu@qmul.ac.uk>; Gabriella Stringer <g.stringer@qmul.ac.uk>; Mohd Adderly Bin Suhaimi <m.suhaimi@qmul.ac.uk>\\n',\n",
       " 'Subject: BAAE - Data Extraction, Cleaning, and Exploration with Python - Session 1\\n',\n",
       " 'When: 23 May 2022 10:00-12:00.\\n',\n",
       " 'Where: Zoom\\n',\n",
       " 'Compulsory Module for BAAE students in year 1  - Session 1\\n',\n",
       " 'Data Extraction, Cleaning, and Exploration with Python\\n',\n",
       " 'Held By: Dr Guven Demirel & Dr Natalia Efremova\\n',\n",
       " 'When: May 23, 2022 10:00 AM London\\n',\n",
       " 'Register in advance for this meeting:\\n',\n",
       " 'https://qmul-ac-uk.zoom.us/meeting/register/tZckcuCtrT4vEtLaTP0axekaS_UL_j2aSQq_\\n',\n",
       " '\\n',\n",
       " 'After registering, you will receive a confirmation email containing information about joining the meeting.\\n',\n",
       " '\\n',\n",
       " '\\n',\n",
       " 'Dear all,\\n',\n",
       " ' \\n',\n",
       " 'Please use the below link to join today session, this should be on the calendar invite for today.\\n',\n",
       " ' \\n',\n",
       " 'https://qmul-ac-uk.zoom.us/j/88574777054?pwd=V0NsQjJJelpKRVBQOVp5WUhlVDhOQT09\\n',\n",
       " ' \\n',\n",
       " 'Best\\n',\n",
       " 'Isabella\\n',\n",
       " '\\n',\n",
       " '\\n',\n",
       " 'Begin forwarded message:\\n',\n",
       " 'From: \"[Shared] SBM PhD support\" <sbmphd-support@qmul.ac.uk>\\n',\n",
       " 'Subject: BAAE - Data Extraction, Cleaning, and Exploration with Python - Session 3\\n',\n",
       " 'Date: 24 May 2022 at 10:49:31 BST\\n',\n",
       " 'To: Kairan Chen <kairan.chen@qmul.ac.uk>, Shang Chen <shang.chen@qmul.ac.uk>, Saeide Jamshidpour Poshtahani <s.jamshidpourposhtahani@qmul.ac.uk>, Zehua Jiang <zehua.jiang@qmul.ac.uk>, Muhammad Taif Khan <taif.khan@qmul.ac.uk>, Shijun Mu <s.mu@qmul.ac.uk>, Ines Saddi Ep Oueslati <i.saddiepoueslati@qmul.ac.uk>, Yuliya Vanzhulova Tavares <y.vanzhulovatavares@qmul.ac.uk>, Guven Demirel <g.demirel@qmul.ac.uk>, Natalia Efremova <n.efremova@qmul.ac.uk>, Loan Quynh Thi Nguyen <loan.nguyen@qmul.ac.uk>, Minqi Feng <minqi.feng@qmul.ac.uk>\\n',\n",
       " 'Cc: Ashraf D M Abumousa <a.d.abumousa@qmul.ac.uk>, Fatima Ali <fatima.ali@qmul.ac.uk>, Jeffery Essuantsi Bondzie <j.e.bondzie@qmul.ac.uk>, Siddharth Chakravarty <s.chakravarty@qmul.ac.uk>, Shabee Ul Haq <shabee.haq@qmul.ac.uk>, Jiawei Huang <jiawei.huang@qmul.ac.uk>, Nabiyla Risfa Izzati <n.izzati@qmul.ac.uk>, Lan Lu <l.lu@qmul.ac.uk>, Gabriella Stringer <g.stringer@qmul.ac.uk>, Mohd Adderly Bin Suhaimi <m.suhaimi@qmul.ac.uk>, Abdullah Ijaz <a.ijaz@qmul.ac.uk>, Shiyu Tang <shiyu.tang@qmul.ac.uk>\\n',\n",
       " '\\n',\n",
       " 'Compulsory Module for BAAE students in year 1  - Session 3\\n',\n",
       " ' \\n',\n",
       " 'Data Extraction, Cleaning, and Exploration with Python\\u202f \\n',\n",
       " ' \\n',\n",
       " 'Held By: Dr Guven Demirel & Dr Natalia Efremova \\n',\n",
       " 'When: May 26, 2022 10:00 AM London \\n',\n",
       " ' \\n',\n",
       " 'Join Zoom Meeting\\n',\n",
       " 'https://qmul-ac-uk.zoom.us/j/83146870352?pwd=VUUzQ20xekZnT3dVVTQ4MGxKdkNJQT09\\n',\n",
       " 'After registering, you will receive a confirmation email containing information about joining the meeting.\\n',\n",
       " '\\n',\n",
       " '\\n',\n",
       " 'Begin forwarded message:\\n',\n",
       " '\\n',\n",
       " 'From: \"[Shared] SBM PhD support\" <sbmphd-support@qmul.ac.uk>\\n',\n",
       " 'Subject: BAAE - Data Extraction, Cleaning, and Exploration with Python - Session 4\\n',\n",
       " 'Date: 24 May 2022 at 10:50:15 BST\\n',\n",
       " 'To: Kairan Chen <kairan.chen@qmul.ac.uk>, Shang Chen <shang.chen@qmul.ac.uk>, Saeide Jamshidpour Poshtahani <s.jamshidpourposhtahani@qmul.ac.uk>, Zehua Jiang <zehua.jiang@qmul.ac.uk>, Muhammad Taif Khan <taif.khan@qmul.ac.uk>, Shijun Mu <s.mu@qmul.ac.uk>, Ines Saddi Ep Oueslati <i.saddiepoueslati@qmul.ac.uk>, Yuliya Vanzhulova Tavares <y.vanzhulovatavares@qmul.ac.uk>, Guven Demirel <g.demirel@qmul.ac.uk>, Natalia Efremova <n.efremova@qmul.ac.uk>, Loan Quynh Thi Nguyen <loan.nguyen@qmul.ac.uk>, Minqi Feng <minqi.feng@qmul.ac.uk>\\n',\n",
       " 'Cc: Ashraf D M Abumousa <a.d.abumousa@qmul.ac.uk>, Fatima Ali <fatima.ali@qmul.ac.uk>, Jeffery Essuantsi Bondzie <j.e.bondzie@qmul.ac.uk>, Siddharth Chakravarty <s.chakravarty@qmul.ac.uk>, Shabee Ul Haq <shabee.haq@qmul.ac.uk>, Jiawei Huang <jiawei.huang@qmul.ac.uk>, Nabiyla Risfa Izzati <n.izzati@qmul.ac.uk>, Lan Lu <l.lu@qmul.ac.uk>, Gabriella Stringer <g.stringer@qmul.ac.uk>, Mohd Adderly Bin Suhaimi <m.suhaimi@qmul.ac.uk>, Abdullah Ijaz <a.ijaz@qmul.ac.uk>, Shiyu Tang <shiyu.tang@qmul.ac.uk>\\n',\n",
       " '\\n',\n",
       " 'Compulsory Module for BAAE students in year 1  - Session 4\\n',\n",
       " ' \\n',\n",
       " 'Data Extraction, Cleaning, and Exploration with Python\\u202f \\n',\n",
       " ' \\n',\n",
       " 'Held By: Dr Guven Demirel & Dr Natalia Efremova  \\n',\n",
       " '                                                                                                     \\n',\n",
       " 'When: May 30, 2022 10:00 PM London \\n',\n",
       " ' \\n',\n",
       " 'Join Zoom Meeting\\n',\n",
       " 'https://qmul-ac-uk.zoom.us/j/82043063022?pwd=T3EwVXh0UHlkOGh4VHBGMlVVRzVWZz09\\n',\n",
       " '\\n',\n",
       " '\\n']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8a1f1cc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dear Isabella,\n",
      "Do we have today's link for the session that will take place at 10. Or we use the same link?\n",
      "Data Extraction, Cleaning, and Exploration with Python\n",
      "Dear all,\n",
      "Date: 24 May 2022 at 10:49:31 BST\n",
      "Data Extraction, Cleaning, and Exploration with Python\n",
      "Date: 24 May 2022 at 10:50:15 BST\n",
      "Data Extraction, Cleaning, and Exploration with Python\n"
     ]
    }
   ],
   "source": [
    "#First thing that we are going to do is to search for the lines we are interested in with \n",
    "#re.search()\n",
    "for line in lines:\n",
    "    line = line.rstrip() #Remove any white spaces at the end of the string:\n",
    "    if re.search(\"^D.*\", line):\n",
    "        print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "576e1515",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://qmul-ac-uk.zoom.us/meeting/register/tZckcuCtrT4vEtLaTP0axekaS_UL_j2aSQq_\n",
      "https://qmul-ac-uk.zoom.us/j/88574777054?pwd=V0NsQjJJelpKRVBQOVp5WUhlVDhOQT09\n",
      "https://qmul-ac-uk.zoom.us/j/83146870352?pwd=VUUzQ20xekZnT3dVVTQ4MGxKdkNJQT09\n",
      "https://qmul-ac-uk.zoom.us/j/82043063022?pwd=T3EwVXh0UHlkOGh4VHBGMlVVRzVWZz09\n"
     ]
    }
   ],
   "source": [
    "for line in lines:\n",
    "    line = line.rstrip() #Remove any white spaces at the end of the string:\n",
    "    if re.search(\"^h\\S+:\", line):\n",
    "        print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "548b6ea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From: [Shared] SBM PhD support <sbmphd-support@qmul.ac.uk>\n",
      "To: Kairan Chen <kairan.chen@qmul.ac.uk>; Shang Chen <shang.chen@qmul.ac.uk>; Saeide Jamshidpour Poshtahani <s.jamshidpourposhtahani@qmul.ac.uk>; Zehua Jiang <zehua.jiang@qmul.ac.uk>; Muhammad Taif Khan <taif.khan@qmul.ac.uk>; Shijun Mu <s.mu@qmul.ac.uk>; Ines Saddi Ep Oueslati <i.saddiepoueslati@qmul.ac.uk>; Yuliya Vanzhulova Tavares <y.vanzhulovatavares@qmul.ac.uk>; Guven Demirel <g.demirel@qmul.ac.uk>; Natalia Efremova <n.efremova@qmul.ac.uk>\n",
      "Cc: Ashraf D M Abumousa <a.d.abumousa@qmul.ac.uk>; Fatima Ali <fatima.ali@qmul.ac.uk>; Jeffery Essuantsi Bondzie <j.e.bondzie@qmul.ac.uk>; Siddharth Chakravarty <s.chakravarty@qmul.ac.uk>; Shabee Ul Haq <shabee.haq@qmul.ac.uk>; Jiawei Huang <jiawei.huang@qmul.ac.uk>; Nabiyla Risfa Izzati <n.izzati@qmul.ac.uk>; Lan Lu <l.lu@qmul.ac.uk>; Gabriella Stringer <g.stringer@qmul.ac.uk>; Mohd Adderly Bin Suhaimi <m.suhaimi@qmul.ac.uk>\n",
      "From: \"[Shared] SBM PhD support\" <sbmphd-support@qmul.ac.uk>\n",
      "To: Kairan Chen <kairan.chen@qmul.ac.uk>, Shang Chen <shang.chen@qmul.ac.uk>, Saeide Jamshidpour Poshtahani <s.jamshidpourposhtahani@qmul.ac.uk>, Zehua Jiang <zehua.jiang@qmul.ac.uk>, Muhammad Taif Khan <taif.khan@qmul.ac.uk>, Shijun Mu <s.mu@qmul.ac.uk>, Ines Saddi Ep Oueslati <i.saddiepoueslati@qmul.ac.uk>, Yuliya Vanzhulova Tavares <y.vanzhulovatavares@qmul.ac.uk>, Guven Demirel <g.demirel@qmul.ac.uk>, Natalia Efremova <n.efremova@qmul.ac.uk>, Loan Quynh Thi Nguyen <loan.nguyen@qmul.ac.uk>, Minqi Feng <minqi.feng@qmul.ac.uk>\n",
      "Cc: Ashraf D M Abumousa <a.d.abumousa@qmul.ac.uk>, Fatima Ali <fatima.ali@qmul.ac.uk>, Jeffery Essuantsi Bondzie <j.e.bondzie@qmul.ac.uk>, Siddharth Chakravarty <s.chakravarty@qmul.ac.uk>, Shabee Ul Haq <shabee.haq@qmul.ac.uk>, Jiawei Huang <jiawei.huang@qmul.ac.uk>, Nabiyla Risfa Izzati <n.izzati@qmul.ac.uk>, Lan Lu <l.lu@qmul.ac.uk>, Gabriella Stringer <g.stringer@qmul.ac.uk>, Mohd Adderly Bin Suhaimi <m.suhaimi@qmul.ac.uk>, Abdullah Ijaz <a.ijaz@qmul.ac.uk>, Shiyu Tang <shiyu.tang@qmul.ac.uk>\n",
      "From: \"[Shared] SBM PhD support\" <sbmphd-support@qmul.ac.uk>\n",
      "To: Kairan Chen <kairan.chen@qmul.ac.uk>, Shang Chen <shang.chen@qmul.ac.uk>, Saeide Jamshidpour Poshtahani <s.jamshidpourposhtahani@qmul.ac.uk>, Zehua Jiang <zehua.jiang@qmul.ac.uk>, Muhammad Taif Khan <taif.khan@qmul.ac.uk>, Shijun Mu <s.mu@qmul.ac.uk>, Ines Saddi Ep Oueslati <i.saddiepoueslati@qmul.ac.uk>, Yuliya Vanzhulova Tavares <y.vanzhulovatavares@qmul.ac.uk>, Guven Demirel <g.demirel@qmul.ac.uk>, Natalia Efremova <n.efremova@qmul.ac.uk>, Loan Quynh Thi Nguyen <loan.nguyen@qmul.ac.uk>, Minqi Feng <minqi.feng@qmul.ac.uk>\n",
      "Cc: Ashraf D M Abumousa <a.d.abumousa@qmul.ac.uk>, Fatima Ali <fatima.ali@qmul.ac.uk>, Jeffery Essuantsi Bondzie <j.e.bondzie@qmul.ac.uk>, Siddharth Chakravarty <s.chakravarty@qmul.ac.uk>, Shabee Ul Haq <shabee.haq@qmul.ac.uk>, Jiawei Huang <jiawei.huang@qmul.ac.uk>, Nabiyla Risfa Izzati <n.izzati@qmul.ac.uk>, Lan Lu <l.lu@qmul.ac.uk>, Gabriella Stringer <g.stringer@qmul.ac.uk>, Mohd Adderly Bin Suhaimi <m.suhaimi@qmul.ac.uk>, Abdullah Ijaz <a.ijaz@qmul.ac.uk>, Shiyu Tang <shiyu.tang@qmul.ac.uk>\n"
     ]
    }
   ],
   "source": [
    "for line in lines:\n",
    "    line = line.rstrip() #Remove any white spaces at the end of the string:\n",
    "    if re.search(\"\\S@\\S\", line):\n",
    "        print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c16ce696",
   "metadata": {},
   "source": [
    "# Matching and extracting data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e693ac22",
   "metadata": {},
   "source": [
    "if we want to extract infromation (or remove), we use **re.findall()**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "63448716",
   "metadata": {},
   "outputs": [],
   "source": [
    "string = \"Milk prices grew from 46p to 51p in the last 5 years\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "68aa4b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers = re.findall('[0-9]+', string) \n",
    "# here [] means \"describe a character you want to find\", it can be a single character or a range\n",
    "# but it is followed by a +, which means \"one or more\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4e065cdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['46', '51', '5']\n"
     ]
    }
   ],
   "source": [
    "print(numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ef812568",
   "metadata": {},
   "outputs": [],
   "source": [
    "letters = re.findall('[a-z]+', string) # here [] means \"one or more digits\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "09d50366",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ilk', 'prices', 'grew', 'from', 'p', 'to', 'p', 'in', 'the', 'last', 'years']\n"
     ]
    }
   ],
   "source": [
    "print(letters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7c81ebcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# non-greedy search: +? mathcing the shortest sequesnce\n",
    "string2 = \"Find : in the following line: From:\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "efc2afbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Find :']\n"
     ]
    }
   ],
   "source": [
    "match = re.findall('^F.+?:', string2) # greedy search finds the shortest sequence\n",
    "print(match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "965785f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Find : in the following line: From:']\n"
     ]
    }
   ],
   "source": [
    "match = re.findall('^F.+:', string2)# non-greedy search finds the longest sequence\n",
    "print(match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e5390a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"today's longest email correspondence was between qmul sudents and the administration office, in which students Jack jack@qmul.ac.uk, Nancy nancy@qmul.ac.uk and Swati swati@qmul.ac.uk were trying to find out the submission deadline fro their coursework.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b2bba18b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['jack@qmul.ac.uk,', 'nancy@qmul.ac.uk', 'swati@qmul.ac.uk']\n"
     ]
    }
   ],
   "source": [
    "emails = re.findall('\\S+@\\S+', text)\n",
    "print(emails)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "330ed1ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['qmul.ac.uk,', 'qmul.ac.uk', 'qmul.ac.uk']\n"
     ]
    }
   ],
   "source": [
    "# to do an even better fine-tuning, we can cut a piece of email address, just a domain name\n",
    "\n",
    "match = re.findall('@([^ ]*)', text) # [^ ] = match a non-blank character, () = match any of them\n",
    "print(match)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdb9d220",
   "metadata": {},
   "source": [
    "we can make it even more precise, e.g. \"^From .@([^ ]*)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "29ec3961",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"From jack@qmul.ac.uk To nancy@qmul.ac.uk\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "41a1909b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['qmul.ac.uk']\n"
     ]
    }
   ],
   "source": [
    "match = re.findall('From .*@([^ ]*)', text) # [^ ] = match a non-blank character, () = match any of them\n",
    "print(match)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a03adcb2",
   "metadata": {},
   "source": [
    "Exercise: can wo find to whom the email was written?\n",
    "Can we extract al the email addresses from our email file?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0448dba6",
   "metadata": {},
   "source": [
    "The **r** in front of a symbol means that the string is to be treated as a raw string. Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "79ebff2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('\\n') # Prints a newline character"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7a1462e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\n\n"
     ]
    }
   ],
   "source": [
    "print(r'\\n') # Escape sequence is not processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d315a8d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extremely excited to participate in the ICML conference! AI CNN cool\n"
     ]
    }
   ],
   "source": [
    "twit = \"extremely excited to participate in the ICML conference! #AI #CNN #cool\"\n",
    "clean_twit = re.sub(r'#', '', twit)\n",
    "print(clean_twit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "aacff2af",
   "metadata": {},
   "outputs": [],
   "source": [
    "complex_sentence  = \"A complex sentence is a sentence that contains an independent clause and one or more subordinate clauses. We use complex sentences when we want to provide more information to support our point. For example: because he didn't do his homework on time, he didn't get a treat after dinner.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e85265f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A complex sentence is a sentence that contains an independent clause and one or more subordinate clauses We use complex sentences when we want to provide more information to support our point For example because he didnt do his homework on time he didnt get a treat after dinner\n"
     ]
    }
   ],
   "source": [
    "no_punct = re.sub(r\"[-()\\\"#/@;:-=~|.?,']\",\"\",complex_sentence)\n",
    "print(no_punct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7487e201",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dealing with special characters\n",
    "# e.g we want to find all the $ signs in the text and extract what comes afterwards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "bd44f56e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['$10.00', '$5.00']\n"
     ]
    }
   ],
   "source": [
    "text = \" we have just received $10.00 for cookies and $5.00 for lemonade.\"\n",
    "match = re.findall('\\$[0-9.]+', text)\n",
    "print(match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "c27edd88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise: consider the following text\n",
    "text_with_money = \"The Covid-19 pandemic has resulted in very high levels of public spending. Current estimates of the cost of Government measures announced so far range from about £4,600 to £6,100 per person in the UK.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "5ca8c160",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['£4,600', '£6,100']\n"
     ]
    }
   ],
   "source": [
    "# please find how much money was spent \n",
    "match = __________\n",
    "\n",
    "print(match)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d94f7480",
   "metadata": {},
   "source": [
    "# Text processing with NLTK"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c583aeb",
   "metadata": {},
   "source": [
    "First, we will look at simple operations with text: tokenisation, lemmatisation etc. We need them to make all words look similar to the machine.\n",
    "\n",
    "- Cleaning texts (regular expressions or one of the following)\n",
    "- Tokenization is to break text into units (words and sentences) : \"I have a dog.\" --> \"I\", \"have\", \"a\", \"dog\", \".\"\n",
    "- Stemming and lemmatization : reducing words into their common stem or lemma. \"has\" -> \"have\", \"dogs\" -> \"dog” etc.\n",
    "- Removal of stop words ( common words such as “a” and “the” that appear in most documents but often provide no significant meaning)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "67f4dd9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nltk\n",
      "  Downloading nltk-3.7-py3-none-any.whl (1.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.5 MB 3.1 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: click in /Users/nataliaefremova/anaconda3/envs/tf/lib/python3.7/site-packages (from nltk) (8.0.3)\n",
      "Requirement already satisfied: joblib in /Users/nataliaefremova/anaconda3/envs/tf/lib/python3.7/site-packages (from nltk) (1.1.0)\n",
      "Requirement already satisfied: tqdm in /Users/nataliaefremova/anaconda3/envs/tf/lib/python3.7/site-packages (from nltk) (4.62.3)\n",
      "Collecting regex>=2021.8.3\n",
      "  Downloading regex-2022.4.24-cp37-cp37m-macosx_10_9_x86_64.whl (289 kB)\n",
      "\u001b[K     |████████████████████████████████| 289 kB 4.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: importlib-metadata in /Users/nataliaefremova/anaconda3/envs/tf/lib/python3.7/site-packages (from click->nltk) (4.8.1)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /Users/nataliaefremova/anaconda3/envs/tf/lib/python3.7/site-packages (from importlib-metadata->click->nltk) (3.10.0.2)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/nataliaefremova/anaconda3/envs/tf/lib/python3.7/site-packages (from importlib-metadata->click->nltk) (3.5.0)\n",
      "Installing collected packages: regex, nltk\n",
      "Successfully installed nltk-3.7 regex-2022.4.24\n"
     ]
    }
   ],
   "source": [
    "! pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "61818f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "6ace69f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/nataliaefremova/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "a668cf67",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /Users/nataliaefremova/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/omw-1.4.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "4c082921",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"This is Guven's class, isn't it?\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7205dc90",
   "metadata": {},
   "source": [
    "You can use the following tokenizers to work with your text, depending on the task in hand:\n",
    "- WhitespaceTokenizer\n",
    "- TreebankWordTokenizer\n",
    "- WordPunctTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "962c2130",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This', 'is', \"Guven's\", 'class,', \"isn't\", 'it?']"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Tokenize a string on whitespace (space, tab, newline). You can use the string split() method instead.\n",
    "tokenizer = nltk.tokenize.WhitespaceTokenizer()\n",
    "tokenizer.tokenize(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec9e408a",
   "metadata": {},
   "source": [
    "The Treebank tokenizer uses regular expressions to tokenize text as in Penn Treebank. \n",
    "This is the method that is invoked by word_tokenize(). \n",
    "It assumes that the text has already been segmented into sentences, e.g. using sent_tokenize().\n",
    "\n",
    "This tokenizer performs the following steps:\n",
    "- split standard contractions, e.g. don't -> do n't and they'll -> they 'll\n",
    "- treat most punctuation characters as separate tokens\n",
    "- split off commas and single quotes, when followed by whitespace\n",
    "- separate periods that appear at the end of line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "7351508f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This', 'is', 'Guven', \"'s\", 'class', ',', 'is', \"n't\", 'it', '?']"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = nltk.tokenize.TreebankWordTokenizer()\n",
    "tokenizer.tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "5d02af30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This', 'is', 'Guven', \"'\", 's', 'class', ',', 'isn', \"'\", 't', 'it', '?']"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tokenize a text into a sequence of alphabetic and non-alphabetic characters, using the regexp \\w+|[^\\w\\s]+.\n",
    "tokenizer = nltk.tokenize.WordPunctTokenizer()\n",
    "tokenizer.tokenize(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e023479",
   "metadata": {},
   "source": [
    "# Lemmatization and stemming: used for extracting lemma and stem of words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa8fbc73",
   "metadata": {},
   "source": [
    "For grammatical reasons, documents are going to use different forms of a word, such as organize, organizes, and organizing. Additionally, there are families of derivationally related words with similar meanings, such as democracy, democratic, and democratization. In many situations, it seems as if it would be useful for a search for one of these words to return documents that contain another word in the set.\n",
    "\n",
    "The goal of both stemming and lemmatization is to reduce inflectional forms and sometimes derivationally related forms of a word to a common base form. For instance:\n",
    "\n",
    "**am, are, is $\\Rightarrow$ be**\n",
    "\n",
    "**car, cars, car's, cars' $\\Rightarrow$ car**\n",
    "\n",
    "\n",
    "The result of this mapping of text will be something like:\n",
    "\n",
    "**the boy's cars are different colors $\\Rightarrow$  the boy car be differ color**\n",
    "\n",
    "\n",
    "However, the two words differ in their flavor. \n",
    "\n",
    "**Stemming** usually refers to a crude heuristic process that chops off the ends of words in the hope of achieving this goal correctly most of the time, and often includes the removal of derivational affixes. \n",
    "\n",
    "**Lemmatization** usually refers to doing things properly with the use of a vocabulary and morphological analysis of words, normally aiming to remove inflectional endings only and to return the base or dictionary form of a word, which is known as the **lemma**. \n",
    "\n",
    "If confronted with the token *saw*, stemming might return just *s*, whereas lemmatization would attempt to return either *see* or *saw* depending on whether the use of the token was as a verb or a noun."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "65f2f2d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['feet', 'wolves', 'cats', 'talked']\n"
     ]
    }
   ],
   "source": [
    "text = \"feet wolves cats talked\"\n",
    "tokenizer = nltk.tokenize.TreebankWordTokenizer()\n",
    "tokens = tokenizer.tokenize(text)\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "0f437edf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'feet wolv cat talk'"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer = nltk.stem.PorterStemmer()\n",
    "\" \".join(stemmer.stem(token) for token in tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "4255e7a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = nltk.stem.WordNetLemmatizer() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "4b99a050",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'foot wolf cat talked'"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\" \".join(lemmatizer.lemmatize(token) for token in tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "326c619e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'talk'"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatizer.lemmatize('talks')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "314a9374",
   "metadata": {},
   "source": [
    "That's all for today: thank you!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
